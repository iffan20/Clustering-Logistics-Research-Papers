{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "615b3e5b-6270-4ab8-a802-64a582e8deb3",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 100px\">\n",
    "\n",
    "# Capstone Project: Classifying Logistics Research Papers\n",
    "## Part 1 : Get text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0494af-bffd-4f7c-b613-702e0f0d799c",
   "metadata": {},
   "source": [
    "---\n",
    "**Part 1: Get Text** | [Part 2: Add Label](02.Add_Label.ipynb) | [Part 3: EDA](03.EDA.ipynb) | [Part 4: Gridsearch Classification](04.Gridsearch_Classification.ipynb) | [Part 5: Neural Network Classification](05.NeuralNet_Classification.ipynb) | [Part 6: Model Evaluation](06.Model_Evaluation.ipynb) | [Part 7: Final Model](07.Final_Model.ipynb) \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85867805-6549-4f80-b4b7-70ce75deaadb",
   "metadata": {},
   "source": [
    "### **This notebook cannot display the output of its cells because it extracts abstracts from confidential research documents.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78189044-9652-4789-9789-210db4e6f368",
   "metadata": {},
   "source": [
    "### Introducion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d82e5c-951a-4130-8da5-965f38eedd86",
   "metadata": {},
   "source": [
    "This notebook focuses on extracting abstracts from research papers authored by logistics students at Burapha University. The extracted abstracts are compiled into a DataFrame, merged with a master dataset containing article names and company information, and sanitized by removing sensitive terms (e.g., company names) to ensure confidentiality. The final dataset is exported as a CSV file, making it suitable for public sharing while maintaining data privacy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68f0d99-b6e3-4e1a-ab5c-fad314a21f24",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98668b59-c08d-4cea-969f-e7d3ce3dc671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mammoth\n",
    "import os\n",
    "import zipfile\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67188d5f-c981-4e03-9c7c-c650666a6781",
   "metadata": {},
   "source": [
    "### Explore files in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d655f1f6-3e4a-4c40-97dd-4542cdb2be5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_dir = '../article'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5ca068-761d-42f2-80a1-912342b2143b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name\n",
    "os.listdir(article_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16f17af-3bda-46dc-bbc2-4eba8179995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of files \n",
    "len(os.listdir(article_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617b116d-f364-4175-8c55-6780a7c7b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What each file represents: An example from the first file in the directory.\n",
    "first_file_path = os.path.join(article_dir, os.listdir(article_dir)[0])\n",
    "with open(first_file_path, \"rb\") as docx_file:\n",
    "    result = mammoth.extract_raw_text(docx_file)\n",
    "    print(result.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babaaba1-52c2-4429-baef-6d41a10d0e72",
   "metadata": {},
   "source": [
    "### Extract abstract from file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e036355d-a325-4c87-a9e3-9d5d8094bc22",
   "metadata": {},
   "source": [
    "The abstract is always contained within the lines following the line that contains or is equal to the word `บทคัดย่อ`, and preceding the line that usually contains the word `บทนำ`. However, some files begin with the following words: `ที่มาและความสำคัญ`, `1ที่มา`, `คำสำคัญ`, `นิยามศัพท์เฉพาะ`, and `ทบทวนวรรณกรรม`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94b1090-4815-4bf5-a1bc-2a2aa4288d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write an fuction to extract abstract\n",
    "def extract_lines_to_dataframe(folder_path):\n",
    "    start_time = time.time()\n",
    "    all_data = []  # List to hold data for the DataFrame\n",
    "\n",
    "    keyword = 'บทคัดย่อ'\n",
    "    stop_phrases = ['บทนำ','ที่มาและความสำคัญ','1ที่มา','คำสำคัญ','นิยามศัพท์เฉพาะ','ทบทวนวรรณกรรม']\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        captured_lines = []\n",
    "\n",
    "        pattern = r'\\\\(.*?)_'\n",
    "        # Extract the student ID and assign it\n",
    "        studentid = int(re.findall(pattern, file_path)[0]) if re.findall(pattern, file_path) else 0        \n",
    "        \n",
    "        try:\n",
    "            # Open and read the DOCX file using Mammoth\n",
    "            with open(file_path, \"rb\") as docx_file:\n",
    "                result = mammoth.extract_raw_text(docx_file)\n",
    "                thai_text = result.value  # Extracted text from the DOCX\n",
    "    \n",
    "            # Split the extracted text into lines\n",
    "            lines = thai_text.split('\\n')\n",
    "            contents = [text.strip() for text in lines if text != ''] # All contents\n",
    "            \n",
    "            # Flag to start capturing text after finding the first matching line\n",
    "            capture_text = False\n",
    "    \n",
    "            for line in lines:\n",
    "                if not capture_text:\n",
    "                    # Check if line contains any of the keywords\n",
    "                    if line.strip() == keyword:\n",
    "                        capture_text = True  # Start capturing from this line onward\n",
    "                    elif keyword in line:\n",
    "                        capture_text = True\n",
    "                        captured_lines.append(line) # Start capturing from this line onward\n",
    "                     \n",
    "                else:\n",
    "                    # Stop capturing if the line contains a stop phrase\n",
    "                    if any(stop_phrase in line for stop_phrase in stop_phrases):\n",
    "                        break\n",
    "                    captured_lines.append(line)\n",
    "            \n",
    "            # Remove unwanted lines\n",
    "            captured_lines = [item for item in captured_lines if item != keyword and item.strip() != '']\n",
    "\n",
    "            # Add the file path and captured lines to the data list\n",
    "            all_data.append({\n",
    "                'file_path' : file_path,\n",
    "                'student_id':  studentid,\n",
    "                'abstract': ' '.join(captured_lines),  # Combine lines into a single string\n",
    "                'content' : ' '.join(contents) # All text in file\n",
    "            })\n",
    "    \n",
    "        except (OSError, ValueError, zipfile.BadZipFile) as e:\n",
    "            # Print error message and skip the problematic file\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "    # Convert the list of dictionaries into a DataFrame\n",
    "    df = pd.DataFrame(all_data)\n",
    "    \n",
    "    end_time  = time.time()\n",
    "    # Calculate and print the runtime\n",
    "    print(f\"Runtime: {end_time - start_time:.0f} seconds for get abstract from {len(os.listdir(folder_path))} files\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8f0ad0-dbce-458e-9f4a-9f5b7b49805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df = extract_lines_to_dataframe(article_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bb920d-6eed-4d71-9ad0-2f7df9499ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a985ce7-654b-449d-b298-acc1af6f86ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df['abstract'] = article_df['abstract'].str.replace('\\t', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72129744-da0e-4f0e-a175-e19d79cc1df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cce467-2c27-4e40-8227-a95414202598",
   "metadata": {},
   "source": [
    "### Master Table\n",
    "This file contains the project name and company name for each project. We will remove the company name from the abstract to avoid confidential and illegal usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529d6dab-16f9-4ca3-aa35-ed69f5475503",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "master_df = pd.read_excel('../data/Student_CoopEdu_MasterData.xlsx')\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6df537-884a-48d7-9f48-89f481586675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge two table\n",
    "df = pd.merge(article_df,master_df, on = 'student_id', how = 'inner')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352fc6a7-eb13-41ab-a086-0c21b51d9477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate project \n",
    "df.drop_duplicates(subset = 'project', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dba1355-8589-42b4-9d5f-f6cb55df4f44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df[['file_path', 'project', 'abstract', 'content', 'company']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336d4b7f-343f-45a2-a898-a6b1e10f7537",
   "metadata": {},
   "source": [
    "### Remove company name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5199b77a-2eaf-4e24-9094-cb5cc58d5324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list contains some company-related words to ensure they are removed from the project name and abstract.\n",
    "sensitive_list = [***]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdb0d8e-a344-4498-b4a5-27bb9552ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove in columns project name and abstract\n",
    "def remove_company_names(row,column_name):\n",
    "    words_in_company = set(row['company'].split())  \n",
    "    cleaned_text = ' '.join([word for word in row[column_name].split() if word not in words_in_company])  \n",
    "   \n",
    "    # Replace sensitive values from sensitive_list\n",
    "    for sensitive_value in sensitive_list:\n",
    "        cleaned_text = cleaned_text.replace(sensitive_value, '')\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15d006c-87a9-4e05-ab4b-d9fcc34f861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to clean columns abstract, project, content\n",
    "df['project'] = df.apply(remove_company_names, axis=1, column_name='project')\n",
    "df['abstract'] = df.apply(remove_company_names, axis=1, column_name='abstract')\n",
    "df['content'] = df.apply(remove_company_names, axis=1, column_name='content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5d7a6a-3f98-42bc-97cb-004f2943e0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df.drop(columns = ['file_path','company'])\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e9d559-57d6-4d24-b213-2cad4af39411",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('../data/reseacrh_text.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new",
   "language": "python",
   "name": "new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
